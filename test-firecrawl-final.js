/**
 * Final Firecrawl Integration Test
 */

require('dotenv').config();
const firecrawlScraper = require('./lib/firecrawl-scraper');

const TEST_URLS = [
    'https://www.bbc.com/mundo',
    'https://elpais.com',
    'https://www.20minutos.es/'
];

async function runTests() {
    console.log('ðŸ”¥ FIRECRAWL INTEGRATION TEST\n');
    console.log('================================\n');

    let successCount = 0;
    let failCount = 0;

    for (let i = 0; i < TEST_URLS.length; i++) {
        const url = TEST_URLS[i];
        console.log(`\nðŸ“ Test ${i + 1}: ${url}`);
        
        try {
            const result = await firecrawlScraper.scrapeArticle(url);
            
            if (result && result.fullText && result.fullText.length > 100) {
                console.log(`âœ… SUCCESS - Scraped ${result.fullText.length} chars`);
                console.log(`   ðŸ“Š Images found: ${result.images.length}`);
                console.log(`   ðŸ“… Metadata: ${result.metadata.title || 'No title'}`);
                successCount++;
            } else {
                console.log('âŒ FAILED - Insufficient content');
                failCount++;
            }
        } catch (error) {
            console.log(`âŒ ERROR: ${error.message}`);
            failCount++;
        }
    }

    console.log('\n\nðŸ“Š FINAL RESULTS');
    console.log('================');
    console.log(`âœ… Successful: ${successCount}/${TEST_URLS.length}`);
    console.log(`âŒ Failed: ${failCount}/${TEST_URLS.length}`);
    console.log(`ðŸ“ˆ Success rate: ${Math.round((successCount / TEST_URLS.length) * 100)}%`);

    const queueStats = firecrawlScraper.getQueueStats();
    console.log(`\nðŸš€ Queue Status: ${queueStats.queued} queued, processing: ${queueStats.processing}`);

    console.log('\nâœ… All tests completed!');
    process.exit(successCount > 0 ? 0 : 1);
}

runTests();

